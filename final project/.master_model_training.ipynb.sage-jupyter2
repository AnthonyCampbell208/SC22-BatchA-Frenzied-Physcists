{"backend_state":"init","connection_file":"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/share/jupyter/runtime/kernel-65f3579e-534d-408e-b850-9831611f036b.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"00f799","input":"","pos":32,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"1aab68","input":"_","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"3e9382","input":"","pos":54,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4cb43d","input":"","pos":55,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"73bbf4","input":"","pos":56,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8942e0","input":"","pos":53,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a6bbba","input":"","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"cd8e02","input":"","pos":62,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"34f581","input":"print(stroke_df.columns)","output":{"0":{"name":"stdout","output_type":"stream","text":"Index(['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n       'smoking_status', 'stroke'],\n      dtype='object')\n"}},"pos":8,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":100,"id":"761f79","input":"fig.write_html(\"results.html\")","pos":61,"type":"cell"}
{"cell_type":"code","exec_count":101,"id":"e57db2","input":"tree_clf = tree.DecisionTreeClassifier(max_depth=4)\ntree_clf = tree_clf.fit(X_train, y_train)\ny_pred = tree_clf.predict(X_test)\nfig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(tree_clf, \n                   feature_names=feature_columns,  \n                   class_names=['Not Stroke','Stroke'],\n                   filled=True, fontsize=10)\n\nplt.savefig(\"dt.jpg\")","output":{"0":{"data":{"image/png":"47722f62bed7c65575ecc3d3aad2c35f1360dcd4","text/plain":"<Figure size 1800x1440 with 1 Axes>"},"exec_count":101,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"8ce659","input":"# This is how many (rows, columns) there are\nstroke_df.shape","output":{"0":{"data":{"text/plain":"(4909, 12)"},"exec_count":11,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"21b69b","input":"clean_stroke_df = pd.get_dummies(stroke_df, columns=['gender','ever_married','work_type','Residence_type','smoking_status']) #Other columns here\nclean_stroke_df.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>stroke</th>\n      <th>gender_Female</th>\n      <th>gender_Male</th>\n      <th>gender_Other</th>\n      <th>...</th>\n      <th>work_type_Never_worked</th>\n      <th>work_type_Private</th>\n      <th>work_type_Self-employed</th>\n      <th>work_type_children</th>\n      <th>Residence_type_Rural</th>\n      <th>Residence_type_Urban</th>\n      <th>smoking_status_Unknown</th>\n      <th>smoking_status_formerly smoked</th>\n      <th>smoking_status_never smoked</th>\n      <th>smoking_status_smokes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9046</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31112</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60182</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1665</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56669</td>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>","text/plain":"      id   age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n0   9046  67.0             0              1             228.69  36.6       1   \n2  31112  80.0             0              1             105.92  32.5       1   \n3  60182  49.0             0              0             171.23  34.4       1   \n4   1665  79.0             1              0             174.12  24.0       1   \n5  56669  81.0             0              0             186.21  29.0       1   \n\n   gender_Female  gender_Male  gender_Other  ...  work_type_Never_worked  \\\n0              0            1             0  ...                       0   \n2              0            1             0  ...                       0   \n3              1            0             0  ...                       0   \n4              1            0             0  ...                       0   \n5              0            1             0  ...                       0   \n\n   work_type_Private  work_type_Self-employed  work_type_children  \\\n0                  1                        0                   0   \n2                  1                        0                   0   \n3                  1                        0                   0   \n4                  0                        1                   0   \n5                  1                        0                   0   \n\n   Residence_type_Rural  Residence_type_Urban  smoking_status_Unknown  \\\n0                     0                     1                       0   \n2                     1                     0                       0   \n3                     0                     1                       0   \n4                     1                     0                       0   \n5                     0                     1                       0   \n\n   smoking_status_formerly smoked  smoking_status_never smoked  \\\n0                               1                            0   \n2                               0                            1   \n3                               0                            0   \n4                               0                            1   \n5                               1                            0   \n\n   smoking_status_smokes  \n0                      0  \n2                      0  \n3                      1  \n4                      0  \n5                      0  \n\n[5 rows x 23 columns]"},"exec_count":12,"output_type":"execute_result"}},"pos":10,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"404cf2","input":"clean_stroke_df = clean_stroke_df.drop(['id'], axis=1)\nclean_stroke_df.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>stroke</th>\n      <th>gender_Female</th>\n      <th>gender_Male</th>\n      <th>gender_Other</th>\n      <th>ever_married_No</th>\n      <th>...</th>\n      <th>work_type_Never_worked</th>\n      <th>work_type_Private</th>\n      <th>work_type_Self-employed</th>\n      <th>work_type_children</th>\n      <th>Residence_type_Rural</th>\n      <th>Residence_type_Urban</th>\n      <th>smoking_status_Unknown</th>\n      <th>smoking_status_formerly smoked</th>\n      <th>smoking_status_never smoked</th>\n      <th>smoking_status_smokes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>","text/plain":"    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n0  67.0             0              1             228.69  36.6       1   \n2  80.0             0              1             105.92  32.5       1   \n3  49.0             0              0             171.23  34.4       1   \n4  79.0             1              0             174.12  24.0       1   \n5  81.0             0              0             186.21  29.0       1   \n\n   gender_Female  gender_Male  gender_Other  ever_married_No  ...  \\\n0              0            1             0                0  ...   \n2              0            1             0                0  ...   \n3              1            0             0                0  ...   \n4              1            0             0                0  ...   \n5              0            1             0                0  ...   \n\n   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n0                       0                  1                        0   \n2                       0                  1                        0   \n3                       0                  1                        0   \n4                       0                  0                        1   \n5                       0                  1                        0   \n\n   work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n0                   0                     0                     1   \n2                   0                     1                     0   \n3                   0                     0                     1   \n4                   0                     1                     0   \n5                   0                     0                     1   \n\n   smoking_status_Unknown  smoking_status_formerly smoked  \\\n0                       0                               1   \n2                       0                               0   \n3                       0                               0   \n4                       0                               0   \n5                       0                               1   \n\n   smoking_status_never smoked  smoking_status_smokes  \n0                            0                      0  \n2                            1                      0  \n3                            0                      1  \n4                            1                      0  \n5                            0                      0  \n\n[5 rows x 22 columns]"},"exec_count":13,"output_type":"execute_result"}},"pos":12,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"0ba315","input":"print(clean_stroke_df.columns)","output":{"0":{"name":"stdout","output_type":"stream","text":"Index(['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi',\n       'stroke', 'gender_Female', 'gender_Male', 'gender_Other',\n       'ever_married_No', 'ever_married_Yes', 'work_type_Govt_job',\n       'work_type_Never_worked', 'work_type_Private',\n       'work_type_Self-employed', 'work_type_children', 'Residence_type_Rural',\n       'Residence_type_Urban', 'smoking_status_Unknown',\n       'smoking_status_formerly smoked', 'smoking_status_never smoked',\n       'smoking_status_smokes'],\n      dtype='object')\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"f0c2a9","input":"feature_columns = list(clean_stroke_df.columns)\nfeature_columns.remove('stroke')\ny_column = 'stroke'\n","pos":14,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"97a0fc","input":"X = clean_stroke_df[feature_columns]\nX.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>gender_Female</th>\n      <th>gender_Male</th>\n      <th>gender_Other</th>\n      <th>ever_married_No</th>\n      <th>ever_married_Yes</th>\n      <th>...</th>\n      <th>work_type_Never_worked</th>\n      <th>work_type_Private</th>\n      <th>work_type_Self-employed</th>\n      <th>work_type_children</th>\n      <th>Residence_type_Rural</th>\n      <th>Residence_type_Urban</th>\n      <th>smoking_status_Unknown</th>\n      <th>smoking_status_formerly smoked</th>\n      <th>smoking_status_never smoked</th>\n      <th>smoking_status_smokes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>","text/plain":"    age  hypertension  heart_disease  avg_glucose_level   bmi  gender_Female  \\\n0  67.0             0              1             228.69  36.6              0   \n2  80.0             0              1             105.92  32.5              0   \n3  49.0             0              0             171.23  34.4              1   \n4  79.0             1              0             174.12  24.0              1   \n5  81.0             0              0             186.21  29.0              0   \n\n   gender_Male  gender_Other  ever_married_No  ever_married_Yes  ...  \\\n0            1             0                0                 1  ...   \n2            1             0                0                 1  ...   \n3            0             0                0                 1  ...   \n4            0             0                0                 1  ...   \n5            1             0                0                 1  ...   \n\n   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n0                       0                  1                        0   \n2                       0                  1                        0   \n3                       0                  1                        0   \n4                       0                  0                        1   \n5                       0                  1                        0   \n\n   work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n0                   0                     0                     1   \n2                   0                     1                     0   \n3                   0                     0                     1   \n4                   0                     1                     0   \n5                   0                     0                     1   \n\n   smoking_status_Unknown  smoking_status_formerly smoked  \\\n0                       0                               1   \n2                       0                               0   \n3                       0                               0   \n4                       0                               0   \n5                       0                               1   \n\n   smoking_status_never smoked  smoking_status_smokes  \n0                            0                      0  \n2                            1                      0  \n3                            0                      1  \n4                            1                      0  \n5                            0                      0  \n\n[5 rows x 21 columns]"},"exec_count":16,"output_type":"execute_result"}},"pos":15,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"d228d5","input":"y = clean_stroke_df[y_column]\ny.head()","output":{"0":{"data":{"text/plain":"0    1\n2    1\n3    1\n4    1\n5    1\nName: stroke, dtype: int64"},"exec_count":17,"output_type":"execute_result"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"1b6a2e","input":"# from sklearn.preprocessing import StandardScaler\n# X_train, X_test, y_train, y_test = train_test_split(\n#      X, y, test_size=0.2, random_state=42)\n\n# y_train.value_counts() \n","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"3e5a0d","input":"import pandas as pd\nimport plotly.express as px\n# So this isn't stratified\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\nfrom matplotlib import pyplot as plt\nimport plotly.figure_factory as ff\nfrom sklearn import tree\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import plot_confusion_matrix\nimport plotly.graph_objects as go\n","pos":0,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"cf05b7","input":"# This one is stratified\ny_train.value_counts()","output":{"0":{"data":{"text/plain":"0    469\n1    376\nName: stroke, dtype: int64"},"exec_count":20,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"b6712c","input":"y_test.value_counts()","output":{"0":{"data":{"text/plain":"0    118\n1     94\nName: stroke, dtype: int64"},"exec_count":21,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"6743d3","input":"clf_rf = RandomForestClassifier(**clf_rf_gs.best_params_)\nclf_rf = clf_rf.fit(X_train,y_train)\ny_pred_rf = clf_rf.predict(X_test)\nacc_rf = metrics.accuracy_score(y_test, y_pred_rf)\nprint('Testing-set Accuracy score is:', acc_rf)\n#print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_rf))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_rf))\ncm = confusion_matrix(y_test, y_pred_rf, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot()\n\nacc = metrics.accuracy_score(y_test, y_pred_rf)\nprec = metrics.precision_score(y_test, y_pred_rf)\nrecall = metrics.recall_score(y_test, y_pred_rf)\nf1 = metrics.f1_score(y_test, y_pred_rf)\nscores['clf_rf_gs'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}","output":{"0":{"ename":"NameError","evalue":"name 'clf_rf_gs' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf_rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mclf_rf_gs\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m      2\u001b[0m clf_rf \u001b[38;5;241m=\u001b[39m clf_rf\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m      3\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m clf_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n","\u001b[0;31mNameError\u001b[0m: name 'clf_rf_gs' is not defined"]}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"c43e61","input":"stroke_df = pd.read_csv(\"./Data/healthcare-dataset-stroke-data.csv\")\n\n# https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"567231","input":"abc = {}\nabc['a'] = {'anthony':1, 'skyler':2}\nabc['b'] = {'anthony':3, 'skyler':4}\n\nabc_df = pd.DataFrame(abc)","pos":26,"type":"cell"}
{"cell_type":"code","exec_count":37,"id":"ad8f3e","input":"","output":{"0":{"data":{"text/plain":"[[1, 3], [2, 4]]"},"exec_count":37,"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"8a30b2","input":"stroke_df.head(20)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9046</td>\n      <td>Male</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>formerly smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51676</td>\n      <td>Female</td>\n      <td>61.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>202.21</td>\n      <td>NaN</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31112</td>\n      <td>Male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60182</td>\n      <td>Female</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1665</td>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56669</td>\n      <td>Male</td>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>formerly smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>53882</td>\n      <td>Male</td>\n      <td>74.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>70.09</td>\n      <td>27.4</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10434</td>\n      <td>Female</td>\n      <td>69.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>94.39</td>\n      <td>22.8</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27419</td>\n      <td>Female</td>\n      <td>59.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>76.15</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>60491</td>\n      <td>Female</td>\n      <td>78.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>58.57</td>\n      <td>24.2</td>\n      <td>Unknown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12109</td>\n      <td>Female</td>\n      <td>81.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>80.43</td>\n      <td>29.7</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12095</td>\n      <td>Female</td>\n      <td>61.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Govt_job</td>\n      <td>Rural</td>\n      <td>120.46</td>\n      <td>36.8</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12175</td>\n      <td>Female</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>104.51</td>\n      <td>27.3</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>8213</td>\n      <td>Male</td>\n      <td>78.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>219.84</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5317</td>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>214.09</td>\n      <td>28.2</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>58202</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>167.41</td>\n      <td>30.9</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>56112</td>\n      <td>Male</td>\n      <td>64.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>191.61</td>\n      <td>37.5</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>34120</td>\n      <td>Male</td>\n      <td>75.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>221.29</td>\n      <td>25.8</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>27458</td>\n      <td>Female</td>\n      <td>60.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>89.22</td>\n      <td>37.8</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>25226</td>\n      <td>Male</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>No</td>\n      <td>Govt_job</td>\n      <td>Urban</td>\n      <td>217.08</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       id  gender   age  hypertension  heart_disease ever_married  \\\n0    9046    Male  67.0             0              1          Yes   \n1   51676  Female  61.0             0              0          Yes   \n2   31112    Male  80.0             0              1          Yes   \n3   60182  Female  49.0             0              0          Yes   \n4    1665  Female  79.0             1              0          Yes   \n5   56669    Male  81.0             0              0          Yes   \n6   53882    Male  74.0             1              1          Yes   \n7   10434  Female  69.0             0              0           No   \n8   27419  Female  59.0             0              0          Yes   \n9   60491  Female  78.0             0              0          Yes   \n10  12109  Female  81.0             1              0          Yes   \n11  12095  Female  61.0             0              1          Yes   \n12  12175  Female  54.0             0              0          Yes   \n13   8213    Male  78.0             0              1          Yes   \n14   5317  Female  79.0             0              1          Yes   \n15  58202  Female  50.0             1              0          Yes   \n16  56112    Male  64.0             0              1          Yes   \n17  34120    Male  75.0             1              0          Yes   \n18  27458  Female  60.0             0              0           No   \n19  25226    Male  57.0             0              1           No   \n\n        work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n0         Private          Urban             228.69  36.6  formerly smoked   \n1   Self-employed          Rural             202.21   NaN     never smoked   \n2         Private          Rural             105.92  32.5     never smoked   \n3         Private          Urban             171.23  34.4           smokes   \n4   Self-employed          Rural             174.12  24.0     never smoked   \n5         Private          Urban             186.21  29.0  formerly smoked   \n6         Private          Rural              70.09  27.4     never smoked   \n7         Private          Urban              94.39  22.8     never smoked   \n8         Private          Rural              76.15   NaN          Unknown   \n9         Private          Urban              58.57  24.2          Unknown   \n10        Private          Rural              80.43  29.7     never smoked   \n11       Govt_job          Rural             120.46  36.8           smokes   \n12        Private          Urban             104.51  27.3           smokes   \n13        Private          Urban             219.84   NaN          Unknown   \n14        Private          Urban             214.09  28.2     never smoked   \n15  Self-employed          Rural             167.41  30.9     never smoked   \n16        Private          Urban             191.61  37.5           smokes   \n17        Private          Urban             221.29  25.8           smokes   \n18        Private          Urban              89.22  37.8     never smoked   \n19       Govt_job          Urban             217.08   NaN          Unknown   \n\n    stroke  \n0        1  \n1        1  \n2        1  \n3        1  \n4        1  \n5        1  \n6        1  \n7        1  \n8        1  \n9        1  \n10       1  \n11       1  \n12       1  \n13       1  \n14       1  \n15       1  \n16       1  \n17       1  \n18       1  \n19       1  "},"exec_count":4,"output_type":"execute_result"}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"c5c14c","input":"clf_rf = RandomForestClassifier()\nparam_grid = {\n    'n_estimators': [x for x in range(200, 500)],\n    'max_features': ['sqrt', 'log2'],\n    'max_depth' : [1,2,3,4,5,6,7],\n    'criterion' :['gini', 'entropy']}\nclf_rf_gs = GridSearchCV(clf_rf, param_grid)\nclf_rf_gs.fit(X_train,y_train)","output":{"0":{"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m)],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m :[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      7\u001b[0m clf_rf_gs \u001b[38;5;241m=\u001b[39m GridSearchCV(clf_rf, param_grid)\n\u001b[0;32m----> 8\u001b[0m clf_rf_gs\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m,y_train)\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"609e8c","input":"stroke_df.isnull()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5105</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5106</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5107</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5108</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5109</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5110 rows × 12 columns</p>\n</div>","text/plain":"         id  gender    age  hypertension  heart_disease  ever_married  \\\n0     False   False  False         False          False         False   \n1     False   False  False         False          False         False   \n2     False   False  False         False          False         False   \n3     False   False  False         False          False         False   \n4     False   False  False         False          False         False   \n...     ...     ...    ...           ...            ...           ...   \n5105  False   False  False         False          False         False   \n5106  False   False  False         False          False         False   \n5107  False   False  False         False          False         False   \n5108  False   False  False         False          False         False   \n5109  False   False  False         False          False         False   \n\n      work_type  Residence_type  avg_glucose_level    bmi  smoking_status  \\\n0         False           False              False  False           False   \n1         False           False              False   True           False   \n2         False           False              False  False           False   \n3         False           False              False  False           False   \n4         False           False              False  False           False   \n...         ...             ...                ...    ...             ...   \n5105      False           False              False   True           False   \n5106      False           False              False  False           False   \n5107      False           False              False  False           False   \n5108      False           False              False  False           False   \n5109      False           False              False  False           False   \n\n      stroke  \n0      False  \n1      False  \n2      False  \n3      False  \n4      False  \n...      ...  \n5105   False  \n5106   False  \n5107   False  \n5108   False  \n5109   False  \n\n[5110 rows x 12 columns]"},"exec_count":5,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"d264ce","input":"\nover = SMOTE(sampling_strategy=0.1, random_state=14)\nX_smote, y_smote = over.fit_resample(X, y)\nunder = RandomUnderSampler(sampling_strategy=0.8, random_state=25)\nX_over, y_over = under.fit_resample(X_smote, y_smote)\n\nX_train, X_test, y_train, y_test = train_test_split(\n     X_over, y_over, test_size=0.2, random_state=42, stratify=y_over)","output":{"0":{"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m over \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m X_smote, y_smote \u001b[38;5;241m=\u001b[39m over\u001b[38;5;241m.\u001b[39mfit_resample(\u001b[43mX\u001b[49m, y)\n\u001b[1;32m      3\u001b[0m under \u001b[38;5;241m=\u001b[39m RandomUnderSampler(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      4\u001b[0m X_over, y_over \u001b[38;5;241m=\u001b[39m under\u001b[38;5;241m.\u001b[39mfit_resample(X_smote, y_smote)\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"f06d6f","input":"stroke_df.isnull().sum()","output":{"0":{"data":{"text/plain":"id                     0\ngender                 0\nage                    0\nhypertension           0\nheart_disease          0\never_married           0\nwork_type              0\nResidence_type         0\navg_glucose_level      0\nbmi                  201\nsmoking_status         0\nstroke                 0\ndtype: int64"},"exec_count":6,"output_type":"execute_result"}},"pos":4,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":68,"id":"93c2e5","input":"fig = go.Figure(data=[go.Table(header=dict(values=list(abc_df.columns)),\n                 cells=dict(values=abc_df.values.tolist()))\n                     ])\nfig.show()","output":{"0":{"data":{"iframe":"57a59d184d89a0537c0c927c5fa8d1a6588020e0"},"exec_count":68,"output_type":"execute_result"}},"pos":28,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":69,"id":"9bb8a6","input":"scores = {} \nscores['metrics'] = {'accuracy': 'accuracy', 'precision':'precision', 'recall':'recall', 'f1_score':'f1_score'}\n","pos":29,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"a1f6d5","input":"stroke_df.duplicated().value_counts()","output":{"0":{"data":{"text/plain":"False    5110\ndtype: int64"},"exec_count":7,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":70,"id":"fdfc2f","input":"\ntree_clf = tree.DecisionTreeClassifier()\ntree_clf = tree_clf.fit(X_train, y_train)\ny_pred_tree = tree_clf.predict(X_test)\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_tree))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred_tree))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_tree))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_tree))\n\nfig, ax = plt.subplots(figsize=(10, 10))\ncm = confusion_matrix(y_test, y_pred_tree, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot(ax=ax)\n\nacc = metrics.accuracy_score(y_test, y_pred_tree)\nprec = metrics.precision_score(y_test, y_pred_tree)\nrecall = metrics.recall_score(y_test, y_pred_tree)\nf1 = metrics.f1_score(y_test, y_pred_tree)\nscores['tree_clf'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\n\n# cm_text = [[str(y) for y in x] for x in cm]\n\n# fig = ff.create_annotated_heatmap(cm, x=[0,1], y= [1,0], annotation_text=cm_text, colorscale='Viridis')\n# fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n#                         x=0.5,\n#                         y=-0.15,\n#                         showarrow=False,\n#                         text=\"Predicted value\",\n#                         xref=\"paper\",\n#                         yref=\"paper\"))\n\n# # add custom yaxis title\n# fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n#                         x=-0.35,\n#                         y=0.5,\n#                         showarrow=False,\n#                         text=\"Real value\",\n#                         textangle=-90,\n#                         xref=\"paper\",\n#                         yref=\"paper\"))\n# # adjust margins to make room for yaxis title\n# fig.update_layout(margin=dict(t=50, l=200))\n\n# # add colorbar\n# fig['data'][0]['showscale'] = True\n# fig.show()\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.8018867924528302\nPrecision: 0.7407407407407407\nRecall: 0.851063829787234\nF1 Score: 0.7920792079207921\n"},"1":{"data":{"image/png":"3062670a8d4c945d34429ab95b9357471c96a5d5","text/plain":"<Figure size 720x720 with 2 Axes>"},"exec_count":70,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":71,"id":"39f266","input":"pd.DataFrame(scores)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metrics</th>\n      <th>tree_clf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>accuracy</td>\n      <td>0.801887</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>precision</td>\n      <td>0.740741</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>recall</td>\n      <td>0.851064</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>f1_score</td>\n      <td>0.792079</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             metrics  tree_clf\naccuracy    accuracy  0.801887\nprecision  precision  0.740741\nrecall        recall  0.851064\nf1_score    f1_score  0.792079"},"exec_count":71,"output_type":"execute_result"}},"pos":33,"type":"cell"}
{"cell_type":"code","exec_count":76,"id":"94cb1c","input":"parameters = {'criterion' :['gini', 'entropy'],\n              'max_features' :['sqrt', 'log2'],\n              'max_depth' :range(1,30),\n              'min_samples_split' :range(1,10),\n              'min_samples_leaf' :range(1,10)} \ntree_gs = GridSearchCV(tree_clf, parameters)\ntree_gs.fit(X_train, y_train)\ntree_clf = tree.DecisionTreeClassifier(**tree_gs.best_params_)\ntree_clf = tree_clf.fit(X_train, y_train)\ny_pred_tree = tree_clf.predict(X_test)\n\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_tree))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred_tree))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_tree))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_tree))\nfig, ax = plt.subplots(figsize=(10, 10))\ncm = confusion_matrix(y_test, y_pred_tree, labels=tree_clf.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot(ax=ax)\nacc = metrics.accuracy_score(y_test, y_pred_tree)\nprec = metrics.precision_score(y_test, y_pred_tree)\nrecall = metrics.recall_score(y_test, y_pred_tree)\nf1 = metrics.f1_score(y_test, y_pred_tree)\nscores['tree_clf_gs'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\n","output":{"0":{"name":"stderr","output_type":"stream","text":"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning:\n\n\n5220 fits failed out of a total of 46980.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5220 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n    check_scalar(\n  File \"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n    raise ValueError(\nValueError: min_samples_split == 1, must be >= 2.\n\n\n/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning:\n\nOne or more of the test scores are non-finite: [       nan 0.68047337 0.61893491 ... 0.72544379 0.73727811 0.71242604]\n\n"},"1":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.7594339622641509\nPrecision: 0.7362637362637363\nRecall: 0.7127659574468085\nF1 Score: 0.7243243243243244\n"},"2":{"data":{"image/png":"ba7768e4317c0c10f62220df31acad4967bb1e22","text/plain":"<Figure size 720x720 with 2 Axes>"},"exec_count":76,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":78,"id":"fff3df","input":"\n\nclf_rf = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators= 200, max_depth=4, criterion='gini')\nclf_rf = clf_rf.fit(X_train,y_train)\ny_pred_rf = clf_rf.predict(X_test)\nacc_rf = metrics.accuracy_score(y_test, y_pred_rf)\nprint('Testing-set Accuracy score is:', acc_rf)\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred_rf))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_rf))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_rf))\ncm = confusion_matrix(y_test, y_pred_rf, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot()\n\nacc = metrics.accuracy_score(y_test, y_pred_rf)\nprec = metrics.precision_score(y_test, y_pred_rf)\nrecall = metrics.recall_score(y_test, y_pred_rf)\nf1 = metrics.f1_score(y_test, y_pred_rf)\nscores['clf_rf'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Testing-set Accuracy score is: 0.7735849056603774\nRecall: 0.8404255319148937\nF1 Score: 0.7669902912621359\n"},"1":{"data":{"image/png":"f143970c061515f9468d818186795a40f4cdc00a","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":78,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"25429b","input":"stroke_df = stroke_df.dropna(axis=0)","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":81,"id":"3a3741","input":"# knn = KNeighborsClassifier(n_neighbors = 5)\n# knn.fit(X_train, y_train)\n# y_pred_knn = knn.predict(X_test)\n# acc_knn = metrics.accuracy_score(y_test,y_pred_knn)\n# print(\"KNN Model Acuuracy is:\", acc_knn)\n# print(\"Precision:\", metrics.precision_score(y_test, y_pred_knn))\n# print(\"Recall:\", metrics.recall_score(y_test, y_pred_knn))\n# print(\"F1 Score:\", metrics.f1_score(y_test, y_pred_knn))\n# cm = confusion_matrix(y_test, y_pred_knn, labels=tree_clf.classes_)\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\n# disp.plot()\n\n\nn_neighbors = list(range(1,30))\n\nhyperparameters = {'n_neighbors':n_neighbors}\nknn_2 = KNeighborsClassifier()\nknn_gs =  GridSearchCV(knn_2, hyperparameters, cv=10)\nknn_gs.fit(X,y)\n\nknn = KNeighborsClassifier(**knn_gs.best_params_)\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\nacc = metrics.accuracy_score(y_test, y_pred_knn)\nprec = metrics.precision_score(y_test, y_pred_knn)\nrecall = metrics.recall_score(y_test, y_pred_knn)\nf1 = metrics.f1_score(y_test, y_pred_knn)\nprint(\"KNN Model Acuuracy is:\", acc_knn)\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred_knn))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_knn))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_knn))\ncm = confusion_matrix(y_test, y_pred_knn, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot()\n\nscores['knn'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}","pos":45,"type":"cell"}
{"cell_type":"code","exec_count":82,"id":"1705ab","input":"pd.DataFrame(scores)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metrics</th>\n      <th>tree_clf</th>\n      <th>tree_clf_gs</th>\n      <th>clf_rf</th>\n      <th>clf_rf_gs</th>\n      <th>knn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>accuracy</td>\n      <td>0.801887</td>\n      <td>0.759434</td>\n      <td>0.773585</td>\n      <td>0.792453</td>\n      <td>0.768868</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>precision</td>\n      <td>0.740741</td>\n      <td>0.736264</td>\n      <td>0.705357</td>\n      <td>0.727273</td>\n      <td>0.718447</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>recall</td>\n      <td>0.851064</td>\n      <td>0.712766</td>\n      <td>0.840426</td>\n      <td>0.851064</td>\n      <td>0.787234</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>f1_score</td>\n      <td>0.792079</td>\n      <td>0.724324</td>\n      <td>0.766990</td>\n      <td>0.784314</td>\n      <td>0.751269</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             metrics  tree_clf  tree_clf_gs    clf_rf  clf_rf_gs       knn\naccuracy    accuracy  0.801887     0.759434  0.773585   0.792453  0.768868\nprecision  precision  0.740741     0.736264  0.705357   0.727273  0.718447\nrecall        recall  0.851064     0.712766  0.840426   0.851064  0.787234\nf1_score    f1_score  0.792079     0.724324  0.766990   0.784314  0.751269"},"exec_count":82,"output_type":"execute_result"}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":83,"id":"5ce127","input":"# Support Vector Classifier \nsvc = SVC(random_state = 42)\nsvc.fit(X_train, y_train)\nsvc_pred = svc.predict(X_test)\nacc_svc = svc.score(X_test, y_test)\nprint(\"SVC Accuracy score is:\", acc_svc)\nprint(\"Precision:\", metrics.precision_score(y_test, svc_pred))\nprint(\"Recall:\", metrics.recall_score(y_test, svc_pred))\nprint(\"F1 Score:\", metrics.f1_score(y_test, svc_pred))\ncm = confusion_matrix(y_test, svc_pred, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot()\n\nacc = metrics.accuracy_score(y_test, svc_pred)\nprec = metrics.precision_score(y_test, svc_pred)\nrecall = metrics.recall_score(y_test, svc_pred)\nf1 = metrics.f1_score(y_test, svc_pred)\nscores['svc'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\n\n# param_grid = {'C': [0.1, 1, 10, 100, 1000],\n#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n#               'kernel': ['rbf']}\n\n# clf = GridSearchCV(tree_clf, parameters)\n# clf.fit(X_train, y_train)\n\n\n# sorted(clf.cv_results_.keys())","output":{"0":{"name":"stdout","output_type":"stream","text":"SVC Accuracy score is: 0.7358490566037735\nPrecision: 0.6696428571428571\nRecall: 0.7978723404255319\nF1 Score: 0.7281553398058253\n"},"1":{"data":{"image/png":"5fbc98b8f286ba19141fdfd17296cdaa0b29fa5f","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":83,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":48,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":84,"id":"340e8c","input":"pd.DataFrame(scores)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metrics</th>\n      <th>tree_clf</th>\n      <th>tree_clf_gs</th>\n      <th>clf_rf</th>\n      <th>clf_rf_gs</th>\n      <th>knn</th>\n      <th>svc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>accuracy</td>\n      <td>0.801887</td>\n      <td>0.759434</td>\n      <td>0.773585</td>\n      <td>0.792453</td>\n      <td>0.768868</td>\n      <td>0.735849</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>precision</td>\n      <td>0.740741</td>\n      <td>0.736264</td>\n      <td>0.705357</td>\n      <td>0.727273</td>\n      <td>0.718447</td>\n      <td>0.669643</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>recall</td>\n      <td>0.851064</td>\n      <td>0.712766</td>\n      <td>0.840426</td>\n      <td>0.851064</td>\n      <td>0.787234</td>\n      <td>0.797872</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>f1_score</td>\n      <td>0.792079</td>\n      <td>0.724324</td>\n      <td>0.766990</td>\n      <td>0.784314</td>\n      <td>0.751269</td>\n      <td>0.728155</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             metrics  tree_clf  tree_clf_gs    clf_rf  clf_rf_gs       knn  \\\naccuracy    accuracy  0.801887     0.759434  0.773585   0.792453  0.768868   \nprecision  precision  0.740741     0.736264  0.705357   0.727273  0.718447   \nrecall        recall  0.851064     0.712766  0.840426   0.851064  0.787234   \nf1_score    f1_score  0.792079     0.724324  0.766990   0.784314  0.751269   \n\n                svc  \naccuracy   0.735849  \nprecision  0.669643  \nrecall     0.797872  \nf1_score   0.728155  "},"exec_count":84,"output_type":"execute_result"}},"pos":50,"type":"cell"}
{"cell_type":"code","exec_count":85,"id":"083f19","input":"     logreg = LogisticRegression(class_weight=\"balanced\")\nlogreg.fit(X_train,y_train)\ny_pred_lr = logreg.predict(X_test)\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred_lr))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred_lr))\nprint(\"F1 Score:\", metrics.f1_score(y_test, y_pred_lr))\ncm = confusion_matrix(y_test, y_pred_lr, labels=tree_clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree_clf.classes_)\ndisp.plot()\n\n\nacc = metrics.accuracy_score(y_test, y_pred_lr)\nprec = metrics.precision_score(y_test, y_pred_lr)\nrecall = metrics.recall_score(y_test, y_pred_lr)\nf1 = metrics.f1_score(y_test, y_pred_lr)\nscores['logreg'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.839622641509434\nPrecision: 0.7941176470588235\nRecall: 0.8617021276595744\nF1 Score: 0.8265306122448979\n"},"1":{"name":"stderr","output_type":"stream","text":"/projects/4ecc52f5-f80b-4322-9a0d-563e88b9d2a6/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning:\n\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n"},"2":{"data":{"image/png":"f792073a77d6e648887d2eb8852635b77fc6c43e","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":85,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":51,"type":"cell"}
{"cell_type":"code","exec_count":86,"id":"5729e5","input":"pd.DataFrame(scores)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metrics</th>\n      <th>tree_clf</th>\n      <th>tree_clf_gs</th>\n      <th>clf_rf</th>\n      <th>clf_rf_gs</th>\n      <th>knn</th>\n      <th>svc</th>\n      <th>logreg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>accuracy</td>\n      <td>0.801887</td>\n      <td>0.759434</td>\n      <td>0.773585</td>\n      <td>0.792453</td>\n      <td>0.768868</td>\n      <td>0.735849</td>\n      <td>0.839623</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>precision</td>\n      <td>0.740741</td>\n      <td>0.736264</td>\n      <td>0.705357</td>\n      <td>0.727273</td>\n      <td>0.718447</td>\n      <td>0.669643</td>\n      <td>0.794118</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>recall</td>\n      <td>0.851064</td>\n      <td>0.712766</td>\n      <td>0.840426</td>\n      <td>0.851064</td>\n      <td>0.787234</td>\n      <td>0.797872</td>\n      <td>0.861702</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>f1_score</td>\n      <td>0.792079</td>\n      <td>0.724324</td>\n      <td>0.766990</td>\n      <td>0.784314</td>\n      <td>0.751269</td>\n      <td>0.728155</td>\n      <td>0.826531</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             metrics  tree_clf  tree_clf_gs    clf_rf  clf_rf_gs       knn  \\\naccuracy    accuracy  0.801887     0.759434  0.773585   0.792453  0.768868   \nprecision  precision  0.740741     0.736264  0.705357   0.727273  0.718447   \nrecall        recall  0.851064     0.712766  0.840426   0.851064  0.787234   \nf1_score    f1_score  0.792079     0.724324  0.766990   0.784314  0.751269   \n\n                svc    logreg  \naccuracy   0.735849  0.839623  \nprecision  0.669643  0.794118  \nrecall     0.797872  0.861702  \nf1_score   0.728155  0.826531  "},"exec_count":86,"output_type":"execute_result"}},"pos":52,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"03727d","input":"stroke_df.gender.value_counts()","output":{"0":{"data":{"text/plain":"Female    2897\nMale      2011\nOther        1\nName: gender, dtype: int64"},"exec_count":9,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":98,"id":"134876","input":"scores_df = pd.DataFrame(scores)\nscores_df = round(scores_df, 2)","pos":58,"type":"cell"}
{"cell_type":"code","exec_count":99,"id":"1cd4d3","input":"data = []\nfor column in scores_df.columns:\n    data.append(scores_df[column].tolist())\nfig = go.Figure(data=[go.Table(header=dict(values=list(scores_df.columns)),\n                 cells=dict(values=data))\n                     ])\nfig.show()","output":{"0":{"data":{"iframe":"1a26fedfed86e0b2b6d53621f823f2757e5734ba"},"exec_count":99,"output_type":"execute_result"}},"pos":59,"type":"cell"}
{"cell_type":"markdown","id":"0f57ec","input":"Our second decision tree classifier is much like our first. Note that our Output is slightly different from the first dtc. Data issues still prominent.\n\n","pos":36,"type":"cell"}
{"cell_type":"markdown","id":"10bade","input":"Overall, we achieved pretty good results. We achieved both a max accuracy of 0.84 and a high f1 score of 0.83 from the logistic regression. The logistic regression performed the best even when compared to the hyper\\-parameter\\-tuned models that we trained. The models that we hyper\\-parameter tuned were the decision tree, random forest, KNN, and the SVC. Performing a grid search, an algorithm for hyperparameter tuning, for random forest improved our results, but ultimately still did not outperform logistic regression. Furthermore, performing a grid search for our decision tree worsened its results. This is because of the lack of scope for hyper parameters our decision tree contained. The decision tree did better than the random forest even though ensemble methods normally work better than just a normal decision tree. This might be due to the lack of features in the data. Because there are so little features when the random forest is training, the smaller decision trees trained on subsets of the features which may be negatively affecting the performance and the models aren't able to discern any new patterns. Our worst performing model was the support vector classifier because it's precision was .67, and it had the lowest number from our range of recall, f1 score, accuracy, and precision. Precision measures the quality of a positive prediction made by the model. The low precision value of the support vector classifier was due to too many false positives, which means the model labelled negative values as positive. \n\n","pos":60,"type":"cell"}
{"cell_type":"markdown","id":"16997d","input":"For our data science project, we created a model that would analyze and predict the probability of having a stroke based on a dataset. Our product uses machine learning to classify individuals with certain traits into categories that indicate stroke risk. We utilized five different \n\n","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"218725","input":"This decision tree shows us what our coding from earlier described. The decision tree is taking the attributes and splitting the data into subsets, predicting a logical outcome based on what it is given. Each of the boxes show important data like, for instance, at the to it says \"age is less than or equal to 53.015\" if this is true than the patient will move to the left, and if it is false it will go to the right, it will then follow this pattern of \"x is less than or equal to y\" until we reach the bottom. \\(Leaves are the decisions\\).  Also you can see that each of the boxes are colored orange or blue, if it is colored blue than that patient in out data had a stroke whereas if it is orange they did not have a stroke, also as the colors get lighter  the gini impurity gets higher, Gini impurity is a function that determines how well a decision tree was split, so the closer to zero it is\nthe better it is when it is closer to 0.5, which is the maximum, that means the tree was split worse.\n\nSplitting at features\n\n","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"3eb13c","input":"A **decision tree classifier** is a form of classifier that maps differences and categories of data for the purpose of easily visualizing it. More importantly, they are able to capture decision\\-making knowledge from supplied data, making this type of classifier a good fit. Important parameters include:\n\n- <u>Criterion</u>: This feature measures the quality of the split, or in other words determines if the division of data is appropriate. In this model, 'gini' refers to gini impurity and entropy refers to the shannon information gain. \n- <u>Max features</u>: This refers to the strategy used to find the best split at a node. \n- <u>Max depth</u>: Setting a max depth limits the number of branches that your tree can have. This can be helpful if there are various variables and a lot of data that could result in an incoherent and unreadable tree. By setting max depths \\(say four or five branches\\) your tree is forced to display only the most relevant information. \n- <u>Min samples split</u>: The minimum number of samples needed to split an internal node. \n- <u>Min samples leaf</u>: The minimum number of samples needed to be included in a leaf node. \n\nVisualization is perk not purpose. Clarify first sentence. \n\n","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"41eb9b","input":"Logistic regression is used to find the probability of something happening by  having the logistic odds of the event be a linear combination of one or more independent variables. We used logistic regression to predict and categorize dependent variable \\(stroke\\)\nand using a set of independent variables \\(age, health conditions\\) to determine a binary out\ncome such as yes or no. When running our model we got a high accuracy score which meant that the correct number of predictions are made and we got a high f1 score which means that our model is performing well.\n\n","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"4b735f","input":"Our model seems to be predicting things very well. It's able to classify the majority of the positive and negative classes. It correctly labeled 90 datapoints as being true negatives and then 80 as being True positives. However, our model seemed to incorrectly label too many things as being positive \\(28 total\\). I.e. we had too many false positives. From this we see that our precision is very low but then we see that it did a good job in predicting the negative class and minimizing False negatives. The recall is at 0.85 which is pretty good for a model. Our model performed well and had a score of .79 for the f1 score and .8 accuracy.  \n\n90 is the best \\(true negatives\\)\n\n14 False negatives\n\n28 false Positives\n\n","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"7fa1dd","input":"<p\n\n<p\n\n<p\n\nWe tried using the &lt;b&gt;Support Vector Classifier&lt;/b&gt; which uses classification algorithms for our two groups.  SVC puts the data into a hyperplane which separates our 'stroke' and 'no stroke' data with a decision boundary line. For our parameters we applied the rbf kernel and gamma which helps with non linear classifier, while the C parameter trades off correct classification of training examples against maximization of the boundary line.  The results weren't amazing, other model learning machines were better, but they were pretty good results. Lacking in precision, the SVC came out with a lot of false positives and fewer false negatives which is better for our data set since we are dealing with strokes. In the real world, it is better to predict a false stroke then to predict no stroke at all.\n\n","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"859892","input":"A random forest is a classification algorithm that consists of multiple decision trees. Each decision tree is run and spits out a ‘vote’ and the random forest’s result is the prediction that the most decision trees voted for. While random forests are quite accurate due to the sheer volume of predictions they make, this sheer volume also makes these models a bit slow to train and ineffective for real\\-time predictions.\n\n","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"93640a","input":"","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"942d7a","input":"In the following lines of code, F.P. utilized five different classifiers to train our data. We used _GridsearchCV_ for hyper\\-parameter tuning, enabling us to find the best combinations of paramaters to **best** classify our data. \n\n","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"a1105b","input":"","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"bf3446","input":"SUHAS/ESMERALDA`\n\n","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"c5fe24","input":"K Nearest Neighbor classifies what where new data belongs between two groups based on its \"neighbors.\" This means the points of data the new data is closest to and making a vote. The closest points on each side each count as a vote so the new data will be classified with the group that has more votes. \n\nUse odd values more. \n\n","pos":47,"type":"cell"}
{"cell_type":"markdown","id":"d6d509","input":"Our outputs when running these models gave us four values: **Accuracy, precision, recall,** \n**and F1 score**. \n\n_**Accuracy**_ _refers to_ the number of correct predictions \\(for both positive and negative class\\) made. \\-&gt; \\(Sensitivity \\+ Specificity\\) / 2 = TP \\+ TN / \\(TP \\+ TN \\+FN \\+ FP\\)\n\n_**Precision**_ _refers to the differences between obtained results regardless of their accuracy._ \\-&gt; true positives / \\(true positives \\+ false positives\\) \n\n_**Recall**_ _refers to_ the ratio between true positives and false negatives, with true positives referring to our model correctly predicting something and false negatives referring to our model incorrectly not predicting something. \\-&gt; true positives / \\(true positives \\+ false negatives\\)\n\n_**F1 Score**_ _refers to the summing up of precision and recall to evaluate the performance of our model._ \\(Why is this scoring metric used vs accuracy\\)\n\nWhat is a false positive vs a false negative? \n\n","pos":25,"type":"cell"}
{"id":0,"time":1656009363072,"type":"user"}
{"last_load":1656004628991,"type":"file"}